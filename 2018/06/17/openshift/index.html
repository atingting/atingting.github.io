<!DOCTYPE HTML>
<html>

<head>
	<link rel="bookmark"  type="image/x-icon"  href="/img/logo_miccall.png"/>
	<link rel="shortcut icon" href="/img/logo_miccall.png">
	
			    <title>
    Fairyting's blog
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    <meta name="keywords" content="miccall" />
    
    	<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/bg.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
</head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">Ting</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">主页</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/about/" title="简历">
		                简历
		            </a>
		        </li>
		        
		        <li>
		            <a href="/gallery/" title="生活">
		                生活
		            </a>
		        </li>
		        
		        <li>
		            <a href="/material/" title="学习资料">
		                学习资料
		            </a>
		        </li>
		        
		        <li>
		            <a href="/learning/" title="Mark">
		                Mark
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
		            
		                <li><a href="https://github.com/atingting" class="icon fa-github"><span class="label">GitHub</span></a></li>
		            
		            
		            
		            
		                <li><a href="mailto:zhangtingting.code@gmail.com" class="icon fa-envelope"><span class="label">Envelope</span></a></li>
		            
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img" style="height: 25rem;background-image: url(/images/distribute.png);background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2 >分布式计算</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <p>最近要做一些分布式计算框架的调研，来记录一下看的东西，以免忘记：</p>
<h3 id="1-什么是分布式计算"><a href="#1-什么是分布式计算" class="headerlink" title="1.什么是分布式计算"></a><strong>1.什么是分布式计算</strong></h3><p>分布式计算简单来说，是把一个大计算任务拆分成多个小计算任务分布到若干台机器上去计算，然后再进行结果汇总，目的在于分析计算海量的数据。海量计算最开始的方案是提高单机计算性能，如大型机，后来由于数据的爆发式增长、单机性能却跟不上，才有分布式计算这种妥协方案。因为计算一旦拆分，问题会变得非常复杂，像一致性、数据完整、通信、容灾、任务调度等问题也都来了。<br>举个例子，产品要求从数据库中100G的用户购买数据，分析出各地域的消费习惯金额等。如果没什么时间要求，通常我们就写个对应的业务处理服务程序，部署到服务器上，让它慢慢跑就是了，我们预计10个小时能处理完。但是后面客户嫌太慢，让想办法加快到半个小时，因此分布式计算产生了，平常开发中类似的需求也很多，总结出来就是，数据量大、单机计算慢，因此我们转向使用多台机器进行运算，现如今分布式计算框架主要有spark,storm,hadoop,AKKA.openshift不知道能不能做分布式，记忆中是结合docker用来做程序部署的.</p>
<h3 id="先看看storm"><a href="#先看看storm" class="headerlink" title="先看看storm:"></a>先看看storm:</h3><p>ApacheStorm是由Twitter开源的分布式实时计算系统。Storm可以非常容易并且可靠的处理无限的数据流。对比Hadoop的批处理，Storm是一个实时的、分布式的、具备高容错的计算系统。Storm应用可以使用不同的编程语言来进行开发。<br>具有如下好处：<br>易于扩展。对于扩展，你只需要添加机器和改变对应的topology（拓扑）设置。Storm使用Hadoop Zookeeper进行集群协调，这样可以充分的保证大型集群的良好运行。<br>1.每条信息的处理都可以得到保证。<br>2.Storm集群管理简易。<br>3.Storm的容错机能：一旦topology递交，Storm会一直运行它直到topology被废除或者被关闭。而在执行中出现错误时，也会由Storm重新分配任务。<br>4.尽管通常使用Java，Storm中的topology可以用任何语言设计。<br><img src="../../../../images/distribute1.png" alt="sample"><br>Nimbus和Supervisor之间的通信依靠Zookeeper来完成，并且Nimbus进程和Supervisor都是快速失败和无状态的.我的理解是如果挂了可以重启，它们可以继续工作。<br>storm里面有一些核心基本概念：包括Topology、Nimbus、Supervisor、Worker、Executor、Task、Spout、Bolt、Tuple、Stream、Stream分组（grouping）等。<br>Topology：一个实时计算应用程序逻辑上被封装在Topology对象中，类似Hadoop中的作业。与作业不同的是，Topology会一直运行直到显式地杀死它。<br>Nimbus：负责资源分配和任务调度。<br>Supervisor：负责接受Nimbus分配的任务，启动和停止属于自己管理的Worker进程。<br>Worker：运行具体处理组件逻辑的进程。<br>Executor：Storm0.8之后，Executor为Worker进程中的具体的物理线程，同一个Spout/Bolt的Task可能会共享一个物理线程，一个Executor中只能运行隶属于同一个Spout/Bolt的Task。<br>Task：每一个Spout/Bolt具体要做的工作，也是各个节点之间进行分组的单位。<br>Spout：在Topology中产生源数据流的组件。通常Spout获取数据源的数据，然后调用nextTuple函数，发射数据供Bolt消费。<br>Bolt：在Topology中接受Spout的数据然后执行处理的组件，Bolt可以执行过滤，函数操作，合并，写数据库等任何操作。Bolt在接收到消息后会调用execute函数，用户可在其中执行自己想要的操作，bolt可以订阅多个由spout或者其他bolt发射的数据流，这样就可以建立复杂的数据流转换网络。<br>Tuple：消息传递的单元。<br>Stream：源源不断传递的Tuple组成了Stream。<br>Stream分组：即消息的分区（partition）方法。Storm中提供若干种实用的分组方式。包括Shuffle、Fields、All、Global、None、Direct、Localorshuffle等。<br>Storm有7种内置的分组方式，也可以通过实现CustomStreamGrouping接口来定义自己的分组。</p>
<p>（1）Shuffle分组：Task中的数据随机分配，可以保证同一级Bolt上的每个Task处理的Tuple数量一致。</p>
<p>（2）Fields分组：根据Tuple中的某一个Filed或者多个Filed的值来划分。比如Stream根据user-id的值来分组，具有相同的user-id值的Tuple会被分发到相同的Task中。</p>
<p>（3）All分组：所有的Tuple都会分发到所有的Task上。</p>
<p>（4）Global分组：整个Stream会选择一个Task作为分发的目的地，通常是具有最新ID的Task。</p>
<p>（5）None分组：也就是你不关心如何在Task中做Stream的分发，目前等同于Shuffle分组。</p>
<p>（6）Direct分组：这是一种特殊的分组方式，也就是产生数据的Spout/Bolt自己明确决定这个Tuple被Bolt的哪些Task所消费。如果Direct分组，需要使用OutputCollector的emitDirect方法来实现。</p>
<p>（7）Localorshuffle分组：如果目标Bolt中的一个或者多个Task和当前产生数据的Task在同一个Worker进程中，那么就走内部的线程间通信，将Tuple直接发给在当前Worker进程中的目的Task。否则，同Shuffle分组<br>storm运行的数据流转换网络Topology可以如下图进行理解：<br><img src="../../../../images/distribute3.png" alt="sample"><br>Topology：在这个Topology中，我们看到Spout和Bolt。在Topology中，我们将Spout和Bolt称之为组件(Components)。一个Topology中，必须同时存在Spout和Bolt，Spout和Bolt数量可以随意，Topology的组件目前只有Spout和Bolt，没有其他组件。</p>
<p>Stream：我们已经知道Spout是从外部数据源中获取数据，以一定的格式将数据传递给Bolt处理。从Spout中源源不断的给Bolt传递数据，形成的这个数据通道我们称之为Stream(流)。因为Strom是一个实时计算的流式处理框架，其不是像hadoop那样，一次性处理一大批的数据(批处理)，以及spark一次性处理一个batch的数据，Storm是不断从外部数据源中获取最新的数据，然后将新的数据传递给Bolt处理(增量处理)。这样不断的获取与传输就形成了这个数据流通道就称之为Stream，因此实时性很高。而Stream传输的最小单位Tuple是有数据格式的，在同一个流中,Tuple的数据格式应该都是一样的；不同流中的数据格式可能相同，也可能不同。</p>
<p>DAG(有向无环图):在storm中，spout和bolt、bolt与bolt之间的数据流向，将整合topology串起来了。topology是DAG即有向无环图，意思就是数据流是有方向的，但是不能形成一个环状。如果形成了一个环状，那么意味着Bolt中的数据还可能传给Spout，spout又要传递给Bolt。这就形成了一个死循环，Stream中的一个数据(Tuple)永远也没办法处理完。</p>
<p>以上看出storm的一些特性，其中实时性很高决定了我们不能选用一般的例如数据库直接读取等数据源，关于数据源的选择：<br>1、实时性<br>Storm是一个实时计算框架。其不能一次性获取所有的数据，进行分析处理。而是Spout不断的从外部数据源中获取最新的数据，然后交给Bolt处理。这意味着，Spout必须要不断的检测外部数据源有没有最新的数据，如果有新数据了，就获取到最新的数据，然后交给Bolt处理。<br>2、容错<br>而且还必须要考虑的是，如果一条数据处理失败了，Spout必须还能再次获取这条数据，否则计算出的结果的误差就会比较大。<br>3、数据路由<br>同时一个Topology中可能会有多个Spout来从外部数据源中获取数据，假设我们有SPOUTA、SPOUTB、SPOUTC，那么某些业务场景下，我们可能希望同一条数据，SPOUTA、SPOUTB、SPOUTC都能获取到。在另外一些业务场景下，可能只希望SPOUTA获取到这条数据。如果数据源不支持路由，意味着，对于不同Topology，需要开发不同的数据获取机制。</p>
<p>而对于这些需求，现有的JMS消息机制，可以满足这个条件。主流的消息中间件，如Kafka、RocketMq等。因此如果要使用strom，需要配合消息中间件使用，也有人会直接使用socket编程实现storm的数据接入，这种数据接入方式比较简单，维护成本较低，但数据量相对于使用消息中间件来说较小。使用Socket采集数据比较麻烦的是，由于Storm的Spout的地址是不定的，无法确定其地址，则前端业务系统就无法将数据准确的发送的某个具体IP地址上的端口中。网上的解决方法如下：</p>
<p>(1) 我们可以使用zookeeper作为传输站，Spout执行后，将本地有效的IP地址及可用正在监控的端口等信息写入zookeeper中，前端业务系统从zookeeper目录中获取该信息。</p>
<p>(2) 使用元数据指导前端业务系统数据发送，Spout将本地IP及端口信息存入元数据管理器中，前端业务系统从元数据管理器中获取该参数信息。</p>
<p>4.数据落地层：<br>(1)同样使用消息中间件，将处理后的数据写入消息中间件之中，后端业务系统再从消息中间件中获取数据。</p>
<p>(2)数据库<br>传统数据库与Storm的接口差不多都相似。一般情况下，数据量不是非常大的情况下可以使用数据库作为数据落地的存储对象。数据库对数据后续处理也是比较方便的，且网络上对数据库的操作也是比较多的，在开发上代价比较小，适合中小量数据存储。</p>
<p>(3)HDFS<br>HDFS及基于Hadoop的分布式文件系统。许多日志分析系统都是基于HDFS搭建出来的，所以开发Storm与HDFS的数据落地接口将很有必要。例如将大批量数据实时处理之后存入Hive中，提供给后端业务系统进行处理，例如日志分析，数据挖掘等等。</p>
<p>Storm的容错机制<br>1Worker进程死亡<br>当仅有Worker进程死亡时，其主机上的Supervisor会尝试重启Worker进程，如果连续重启都失败，当超过一定的失败次数之后，Nimbus会在其他主机上重启Worker。</p>
<p>当Supervisor死亡时，如果某个主机上的Worker死亡了，由于没有Supervisor，所以无法在本机重启Worker，但会在其他主机上重启Worker，当Supervisor重启以后，会将本机的Worker重启，而之间在其他主机上重启的Worker则会消失，例如之前node2有三个Worker，node3有三个Worker，当node2的Supervisor死亡并且kill掉一个Worker之后，node3出现四个Worker，重启node2的Supervisor之后，node2会重启一个Worker，恢复成三个Worker，node3kill掉多余的一个Worker，也恢复成三个Worker。</p>
<p>当Nimbus死亡时，Worker也会继续执行，但是某个Worker死亡时不会像Supervisor死亡时安排到其他主机上执行，因此如果Worker全部死亡，则任务执行失败。</p>
<p>集群中的Worker是均匀分配到各节点上的，例如一个作业有三个Worker时，会在一个节点（例如node2）分配两个Worker，在一个节点（例如node3）分配一个Worker，当再启动一个需要三个Worker的作业时，会在node2分配一个Worker，在node3分配两个Worker。</p>
<p>2 Nimbus或者Supervisor进程死亡<br>Nimbus和Supervisor被设计成是快速失败且无状态的，他们的状态都保存在ZooKeeper或者磁盘上，如果这两个进程死亡，它们不会像Worker一样自动重启，但是集群上的作业仍然可以在Worker中运行，并且他们重启之后会像什么都没发生一样正常工作。</p>
<p>3ZooKeeper停止<br>ZooKeeper的停止同样不会影响已有的作业运行，此时kill掉Worker以后过段时间仍会在本机重启一个Worker。</p>
<p>综上所述，只有Nimbus失败并且所有Worker都失败之后才会影响集群上的作业运行，除此之外Storm集群的容错机制可以保证作业运行的可靠性。</p>
<p>对于storm的理解，在网上找了一个例子，用storm来进行分词，代码如下（亲测可运行）：</p>
<p>新建类SentenceSpout.java（数据流生成者）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">importjava.util.Map;</span><br><span class="line"></span><br><span class="line">importorg.apache.storm.spout.SpoutOutputCollector;</span><br><span class="line">importorg.apache.storm.task.TopologyContext;</span><br><span class="line">importorg.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line">importorg.apache.storm.topology.base.BaseRichSpout;</span><br><span class="line">importorg.apache.storm.tuple.Fields;</span><br><span class="line">importorg.apache.storm.tuple.Values;</span><br><span class="line">importorg.apache.storm.utils.Utils;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*向后端发射tuple数据流</span><br><span class="line">*@authorsoul</span><br><span class="line">*</span><br><span class="line">*/</span><br><span class="line">public class SentenceSpout extends BaseRichSpout&#123;</span><br><span class="line"></span><br><span class="line">//BaseRichSpout是ISpout接口和IComponent接口的简单实现，接口对用不到的方法提供了默认的实现</span><br><span class="line"></span><br><span class="line">    private SpoutOutputCollectorcollector;</span><br><span class="line">    private String[] sentences=&#123;</span><br><span class="line">        &quot;mynameissoul&quot;,</span><br><span class="line">        &quot;imaboy&quot;,</span><br><span class="line">        &quot;ihaveadog&quot;,</span><br><span class="line">        &quot;mydoghasfleas&quot;,</span><br><span class="line">        &quot;mygirlfriendisbeautiful&quot;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    privateintindex=0;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*open()方法中是ISpout接口中定义，在Spout组件初始化时被调用。</span><br><span class="line">*open()接受三个参数:一个包含Storm配置的Map,一个TopologyContext对象，</span><br><span class="line">提供了topology中组件的信息,SpoutOutputCollector对象提供发射tuple的方法。</span><br><span class="line">*在这个例子中,我们不需要执行初始化,只是简单的存储在一个SpoutOutputCollector实例变量。</span><br><span class="line">*/</span><br><span class="line">public void open(Mapconf,TopologyContextcontext,SpoutOutputCollectorcollector)&#123;</span><br><span class="line">//TODOAuto-generatedmethodstub</span><br><span class="line">    this.collector=collector;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*nextTuple()方法是任何Spout实现的核心。</span><br><span class="line">*Storm调用这个方法，向输出的collector发出tuple。</span><br><span class="line">*在这里,我们只是发出当前索引的句子，并增加该索引准备发射下一个句子。</span><br><span class="line">*/</span><br><span class="line">public void nextTuple()&#123;</span><br><span class="line">//collector.emit(newValues(&quot;helloworldthisisatest&quot;));</span><br><span class="line"></span><br><span class="line">//TODOAuto-generatedmethodstub</span><br><span class="line">    this.collector.emit(newValues(sentences[index]));</span><br><span class="line">        index++;</span><br><span class="line">        if(index&gt;=sentences.length)&#123;</span><br><span class="line">        index=0;</span><br><span class="line">    &#125;</span><br><span class="line">    Utils.sleep(1);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*declareOutputFields是在IComponent接口中定义的，所有Storm的组件（spout和bolt）都必须实现这个接口</span><br><span class="line">*用于告诉Storm流组件将会发出那些数据流，每个流的tuple将包含的字段</span><br><span class="line">*/</span><br><span class="line">public void declareOutputFields(OutputFieldsDeclarerdeclarer)&#123;</span><br><span class="line">//TODOAuto-generatedmethodstub</span><br><span class="line"></span><br><span class="line">    declarer.declare(newFields(&quot;sentence&quot;));//告诉组件发出数据流包含sentence字段</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>新建类SplitSentenceBolt.java（单词分割器）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">importjava.util.Map;</span><br><span class="line"></span><br><span class="line">importorg.apache.storm.task.OutputCollector;</span><br><span class="line">importorg.apache.storm.task.TopologyContext;</span><br><span class="line">importorg.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line">importorg.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line">importorg.apache.storm.tuple.Fields;</span><br><span class="line">importorg.apache.storm.tuple.Tuple;</span><br><span class="line">importorg.apache.storm.tuple.Values;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*订阅sentencespout发射的tuple流，实现分割单词</span><br><span class="line">*@authorsoul</span><br><span class="line">*</span><br><span class="line">*/</span><br><span class="line">publicclassSplitSentenceBoltextendsBaseRichBolt&#123;</span><br><span class="line">//BaseRichBolt是IComponent和IBolt接口的实现</span><br><span class="line">//继承这个类，就不用去实现本例不关心的方法</span><br><span class="line"></span><br><span class="line">private OutputCollectorcollector;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*prepare()方法类似于ISpout的open()方法。</span><br><span class="line">*这个方法在blot初始化时调用，可以用来准备bolt用到的资源,比如数据库连接。</span><br><span class="line">*本例子和SentenceSpout类一样,SplitSentenceBolt类不需要太多额外的初始化,</span><br><span class="line">*所以prepare()方法只保存OutputCollector对象的引用。</span><br><span class="line">*/</span><br><span class="line">public void prepare(MapstormConf,TopologyContextcontext,OutputCollectorcollector)&#123;</span><br><span class="line">//TODOAuto-generatedmethodstub</span><br><span class="line">    this.collector=collector;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*SplitSentenceBolt核心功能是在类IBolt定义execute()方法，这个方法是IBolt接口中定义。</span><br><span class="line">*每次Bolt从流接收一个订阅的tuple，都会调用这个方法。</span><br><span class="line">*本例中,收到的元组中查找“sentence”的值,</span><br><span class="line">*并将该值拆分成单个的词,然后按单词发出新的tuple。</span><br><span class="line">*/</span><br><span class="line">public void execute(Tupleinput)&#123;</span><br><span class="line">//TODOAuto-generatedmethodstub</span><br><span class="line">    Stringsentence=input.getStringByField(&quot;sentence&quot;);</span><br><span class="line">    String[]words=sentence.split(&quot;&quot;);</span><br><span class="line">    for(Stringword:words)&#123;</span><br><span class="line">    this.collector.emit(newValues(word));//向下一个bolt发射数据</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*plitSentenceBolt类定义一个元组流,每个包含一个字段(“word”)。</span><br><span class="line">*/</span><br><span class="line">public void declareOutputFields(OutputFieldsDeclarerdeclarer)&#123;</span><br><span class="line">//TODOAuto-generatedmethodstub</span><br><span class="line">    declarer.declare(newFields(&quot;word&quot;));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>新建类WordCountBolt.java（单词计数器）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">importjava.util.HashMap;</span><br><span class="line">importjava.util.Map;</span><br><span class="line"></span><br><span class="line">importorg.apache.storm.task.OutputCollector;</span><br><span class="line">importorg.apache.storm.task.TopologyContext;</span><br><span class="line">importorg.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line">importorg.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line">importorg.apache.storm.tuple.Fields;</span><br><span class="line">importorg.apache.storm.tuple.Tuple;</span><br><span class="line">importorg.apache.storm.tuple.Values;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*订阅splitsentencebolt的输出流，实现单词计数，并发送当前计数给下一个bolt</span><br><span class="line">*@authorsoul</span><br><span class="line">*</span><br><span class="line">*/</span><br><span class="line">public class WordCountBolt extends BaseRichBolt&#123;</span><br><span class="line">private OutputCollectorcollector;</span><br><span class="line">//存储单词和对应的计数</span><br><span class="line">private HashMap&lt;String,Long&gt; counts=null;//注：不可序列化对象需在prepare中实例化</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*大部分实例变量通常是在prepare()中进行实例化，这个设计模式是由topology的部署方式决定的</span><br><span class="line">*因为在部署拓扑时,组件spout和bolt是在网络上发送的序列化的实例变量。</span><br><span class="line">*如果spout或bolt有任何non-serializable实例变量在序列化之前被实例化(例如,在构造函数中创建)</span><br><span class="line">*会抛出NotSerializableException并且拓扑将无法发布。</span><br><span class="line">*本例中因为HashMap是可序列化的,所以可以安全地在构造函数中实例化。</span><br><span class="line">*但是，通常情况下最好是在构造函数中对基本数据类型和可序列化的对象进行复制和实例化</span><br><span class="line">*而在prepare()方法中对不可序列化的对象进行实例化。</span><br><span class="line">*/</span><br><span class="line">public void prepare(MapstormConf,TopologyContextcontext,OutputCollectorcollector)&#123;</span><br><span class="line">//TODOAuto-generatedmethodstub</span><br><span class="line">    this.collector=collector;</span><br><span class="line">    this.counts=newHashMap&lt;String,Long&gt;();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*在execute()方法中,我们查找的收到的单词的计数(如果不存在，初始化为0)</span><br><span class="line">*然后增加计数并存储,发出一个新的词和当前计数组成的二元组。</span><br><span class="line">*发射计数作为流允许拓扑的其他bolt订阅和执行额外的处理。</span><br><span class="line">*/</span><br><span class="line">public void execute(Tupleinput)&#123;</span><br><span class="line">//TODOAuto-generatedmethodstub</span><br><span class="line"></span><br><span class="line">    Stringword=input.getStringByField(&quot;word&quot;);</span><br><span class="line">    Longcount=this.counts.get(word);</span><br><span class="line">    if(count==null)&#123;</span><br><span class="line">    count=0L;//如果不存在，初始化为0</span><br><span class="line">&#125;</span><br><span class="line">    count++;//增加计数</span><br><span class="line">    this.counts.put(word,count);//存储计数</span><br><span class="line">    this.collector.emit(newValues(word,count));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*</span><br><span class="line">*/</span><br><span class="line">public void declareOutputFields(OutputFieldsDeclarerdeclarer)&#123;</span><br><span class="line">//TODOAuto-generatedmethodstub</span><br><span class="line">//声明一个输出流，其中tuple包括了单词和对应的计数，向后发射</span><br><span class="line">//其他bolt可以订阅这个数据流进一步处理</span><br><span class="line">    declarer.declare(newFields(&quot;word&quot;,&quot;count&quot;));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>新建类ReportBolt.java（报告生成器）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">importjava.util.ArrayList;</span><br><span class="line">importjava.util.Collections;</span><br><span class="line">importjava.util.HashMap;</span><br><span class="line">importjava.util.Map;</span><br><span class="line"></span><br><span class="line">importorg.apache.storm.task.OutputCollector;</span><br><span class="line">importorg.apache.storm.task.TopologyContext;</span><br><span class="line">importorg.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line">importorg.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line">importorg.apache.storm.tuple.Tuple;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*生成一份报告</span><br><span class="line">*@authorsoul</span><br><span class="line">*</span><br><span class="line">*/</span><br><span class="line">publicclassReportBoltextendsBaseRichBolt&#123;</span><br><span class="line"></span><br><span class="line">privateHashMap&lt;String,Long&gt;counts=null;//保存单词和对应的计数</span><br><span class="line"></span><br><span class="line">public void prepare(MapstormConf,TopologyContextcontext,OutputCollectorcollector)&#123;</span><br><span class="line">//TODOAuto-generatedmethodstub</span><br><span class="line"></span><br><span class="line">    this.counts=newHashMap&lt;String,Long&gt;();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public void execute(Tupleinput)&#123;</span><br><span class="line">    //TODOAuto-generatedmethodstub</span><br><span class="line"></span><br><span class="line">    Stringword=input.getStringByField(&quot;word&quot;);</span><br><span class="line">    Longcount=input.getLongByField(&quot;count&quot;);</span><br><span class="line">    this.counts.put(word,count);</span><br><span class="line"></span><br><span class="line">    //实时输出</span><br><span class="line">    System.out.println(&quot;结果:&quot;+this.counts);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public void declareOutputFields(OutputFieldsDeclarerdeclarer)&#123;</span><br><span class="line">//TODOAuto-generatedmethodstub</span><br><span class="line">//这里是末端bolt，不需要发射数据流，这里无需定义</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*cleanup是IBolt接口中定义</span><br><span class="line">*Storm在终止一个bolt之前会调用这个方法</span><br><span class="line">*本例我们利用cleanup()方法在topology关闭时输出最终的计数结果</span><br><span class="line">*通常情况下，cleanup()方法用来释放bolt占用的资源，如打开的文件句柄或数据库连接</span><br><span class="line">*但是当Storm拓扑在一个集群上运行，IBolt.cleanup()方法不能保证执行（这里是开发模式，生产环境不要这样做）。</span><br><span class="line">*/</span><br><span class="line">public void cleanup()&#123;</span><br><span class="line">    System.out.println(&quot;----------FINALCOUNTS-----------&quot;);</span><br><span class="line"></span><br><span class="line">    ArrayList&lt;String&gt;keys=newArrayList&lt;String&gt;();</span><br><span class="line">    keys.addAll(this.counts.keySet());</span><br><span class="line">    Collections.sort(keys);</span><br><span class="line">    for(Stringkey:keys)&#123;</span><br><span class="line">    System.out.println(key+&quot;:&quot;+this.counts.get(key));</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(&quot;----------------------------&quot;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>修改程序主入口App.java<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">importorg.apache.storm.Config;</span><br><span class="line">importorg.apache.storm.LocalCluster;</span><br><span class="line">importorg.apache.storm.topology.TopologyBuilder;</span><br><span class="line">importorg.apache.storm.tuple.Fields;</span><br><span class="line">importorg.apache.storm.utils.Utils;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">*实现单词计数topology</span><br><span class="line">*</span><br><span class="line">*/</span><br><span class="line">publicclassApp</span><br><span class="line">&#123;</span><br><span class="line">privatestaticfinalStringSENTENCE_SPOUT_ID=&quot;sentence-spout&quot;;</span><br><span class="line">privatestaticfinalStringSPLIT_BOLT_ID=&quot;split-bolt&quot;;</span><br><span class="line">privatestaticfinalStringCOUNT_BOLT_ID=&quot;count-bolt&quot;;</span><br><span class="line">privatestaticfinalStringREPORT_BOLT_ID=&quot;report-bolt&quot;;</span><br><span class="line">privatestaticfinalStringTOPOLOGY_NAME=&quot;word-count-topology&quot;;</span><br><span class="line"></span><br><span class="line">public static void main(String[]args)//throwsException</span><br><span class="line">&#123;</span><br><span class="line">    //System.out.println(&quot;HelloWorld!&quot;);</span><br><span class="line">    //实例化spout和bolt</span><br><span class="line"></span><br><span class="line">    SentenceSpoutspout=newSentenceSpout();</span><br><span class="line">    SplitSentenceBoltsplitBolt=newSplitSentenceBolt();</span><br><span class="line">    WordCountBoltcountBolt=newWordCountBolt();</span><br><span class="line">    ReportBoltreportBolt=newReportBolt();</span><br><span class="line"></span><br><span class="line">    TopologyBuilderbuilder=newTopologyBuilder();//创建了一个TopologyBuilder实例</span><br><span class="line"></span><br><span class="line">    //TopologyBuilder提供流式风格的API来定义topology组件之间的数据流</span><br><span class="line"></span><br><span class="line">    //builder.setSpout(SENTENCE_SPOUT_ID,spout);//注册一个sentencespout</span><br><span class="line"></span><br><span class="line">    //设置两个Executeor(线程)，默认一个</span><br><span class="line">    builder.setSpout(SENTENCE_SPOUT_ID,spout,2);</span><br><span class="line"></span><br><span class="line">    //SentenceSpout--&gt;SplitSentenceBolt</span><br><span class="line"></span><br><span class="line">    //注册一个bolt并订阅sentence发射出的数据流，</span><br><span class="line">    //shuffleGrouping方法告诉Storm要将SentenceSpout发射的tuple随机均匀的分发给SplitSentenceBolt的实例</span><br><span class="line">    //builder.setBolt(SPLIT_BOLT_ID,splitBolt).shuffleGrouping(SENTENCE_SPOUT_ID);</span><br><span class="line"></span><br><span class="line">    //SplitSentenceBolt单词分割器设置4个Task，2个Executeor(线程)</span><br><span class="line">    builder.setBolt(SPLIT_BOLT_ID,splitBolt,2).setNumTasks(4).shuffleGrouping(SENTENCE_SPOUT_ID);</span><br><span class="line"></span><br><span class="line">    //SplitSentenceBolt--&gt;WordCountBolt</span><br><span class="line"></span><br><span class="line">    //fieldsGrouping将含有特定数据的tuple路由到特殊的bolt实例中</span><br><span class="line">    //这里fieldsGrouping()方法保证所有“word”字段相同的tuuple会被路由到同一个WordCountBolt实例中</span><br><span class="line">    //builder.setBolt(COUNT_BOLT_ID,countBolt).fieldsGrouping(SPLIT_BOLT_ID,newFields(&quot;word&quot;));</span><br><span class="line"></span><br><span class="line">    //WordCountBolt单词计数器设置4个Executeor(线程)</span><br><span class="line">    builder.setBolt(COUNT_BOLT_ID,countBolt,4).fieldsGrouping(SPLIT_BOLT_ID,newFields(&quot;word&quot;));</span><br><span class="line"></span><br><span class="line">    //WordCountBolt--&gt;ReportBolt</span><br><span class="line"></span><br><span class="line">    //globalGrouping是把WordCountBolt发射的所有tuple路由到唯一的ReportBolt</span><br><span class="line">    builder.setBolt(REPORT_BOLT_ID,reportBolt).globalGrouping(COUNT_BOLT_ID);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    Configconfig=newConfig();</span><br><span class="line">    //Config类是一个HashMap&lt;String,Object&gt;的子类，用来配置topology运行时的行为</span><br><span class="line">    //设置worker数量</span><br><span class="line">    //config.setNumWorkers(2);</span><br><span class="line">    LocalClustercluster=newLocalCluster();</span><br><span class="line"></span><br><span class="line">    //本地提交</span><br><span class="line">    cluster.submitTopology(TOPOLOGY_NAME,config,builder.createTopology());</span><br><span class="line"></span><br><span class="line">    Utils.sleep(10000);</span><br><span class="line">    cluster.killTopology(TOPOLOGY_NAME);</span><br><span class="line">    cluster.shutdown();</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>参考资料：<br><a href="http://storm.apache.org/about/integrates.html" target="_blank" rel="noopener">http://storm.apache.org/about/integrates.html</a><br><a href="https://www.cnblogs.com/langtianya/p/5199529.html" target="_blank" rel="noopener">https://www.cnblogs.com/langtianya/p/5199529.html</a><br><a href="https://blog.csdn.net/uisoul/article/details/77990260" target="_blank" rel="noopener">https://blog.csdn.net/uisoul/article/details/77990260</a><br><a href="https://blog.csdn.net/uisoul/article/details/77989927" target="_blank" rel="noopener">https://blog.csdn.net/uisoul/article/details/77989927</a><br><a href="https://blog.csdn.net/CSDN_WANGQI/article/details/53306603" target="_blank" rel="noopener">https://blog.csdn.net/CSDN_WANGQI/article/details/53306603</a><br><a href="https://blog.csdn.net/csdn_wangqi/article/details/53317095" target="_blank" rel="noopener">https://blog.csdn.net/csdn_wangqi/article/details/53317095</a><br><a href="https://blog.csdn.net/qq_37095882/article/category/7055953" target="_blank" rel="noopener">https://blog.csdn.net/qq_37095882/article/category/7055953</a><br><a href="https://blog.csdn.net/cuihaolong/article/details/52652686" target="_blank" rel="noopener">https://blog.csdn.net/cuihaolong/article/details/52652686</a><br><a href="https://www.jianshu.com/p/7e5fc624861b" target="_blank" rel="noopener">https://www.jianshu.com/p/7e5fc624861b</a><br><a href="https://blog.csdn.net/blogchong/article/details/41478357" target="_blank" rel="noopener">https://blog.csdn.net/blogchong/article/details/41478357</a></p>
<h3 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h3><p>1.ZooKeeper是什么？<br>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。它包括了文件系统和通知机制。</p>
<p>Zookeeper是一个基于观察者模式设计的分布式服务管理框架，负责存储和管理相关数据，接收观察者的注册。一旦这些数据的状态发生变化，zookeeper就负责通知那些已经在zookeeper集群进行注册并关心这些状态发生变化的观察者，以便观察者执行相关操作。</p>
<p>Zookeeper使用的数据结构为树形结构，根节点为”/“。Zookeeper集群中的节点，根据其身份特性分为leader、follower、observer。leader负责客户端writer类型的请求；follower负责客户端reader类型的请求，并参与leader选举；observer是特殊的follower，可以接收客户端reader请求，但是不会参与选举，可以用来扩容系统支撑能力，提高读取速度。<br>Zookeeper与客户端：<br><img src="../../../../images/zookeeper3.png" alt="sample"></p>
<p>zookeeper有如下特征：</p>
<p>1.最终一致性：client不论连接到哪个Server，展示给它都是同一个视图，这是zookeeper最重要的性能。 </p>
<p>2.可靠性：具有简单、健壮、良好的性能，如果消息被到一台服务器接受，那么它将被所有的服务器接受。 </p>
<p>3.实时性：Zookeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。 </p>
<p>4.等待无关（wait-free）：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。 </p>
<p>5.原子性：更新只能成功或者失败，没有中间状态。 </p>
<p>6.顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。 </p>
<p>2.ZooKeeper可以用来干什么？</p>
<p>1.配置管理<br>比如我在搭建hadoop的HDFS的时候，需要在一个主机器上（Master节点）配置好HDFS需要的各种配置文件，然后通过scp命令把这些配置文件拷贝到其他节点上，这样各个机器拿到的配置信息是一致的，才能成功运行起来HDFS服务。Zookeeper提供了这样的一种服务：一种集中管理配置的方法，我们在这个集中的地方修改了配置，所有对这个配置感兴趣的都可以获得变更。这样就省去手动拷贝配置了，还保证了可靠和一致性。</p>
<p>2.分布式锁<br>单机程序的各个进程需要对互斥资源进行访问时需要加锁，那分布式程序分布在各个主机上的进程对互斥资源进行访问时也需要加锁。很多分布式系统有多个可服务的窗口，但是在某个时刻只让一个服务去干活，当这台服务出问题的时候锁释放，立即fail over到另外的服务。在ZooKeeper中叫Leader Election(leader选举)。</p>
<p>3.集群管理<br>在分布式的集群中，经常会由于各种原因，比如硬件故障，软件故障，网络问题，有些节点会进进出出。有新的节点加入进来，也有老的节点退出集群。这个时候，集群中有些机器（比如Master节点）需要感知到这种变化，然后根据这种变化做出对应的决策。例如HDFS中namenode是通过datanode的心跳机制来实现上述感知的，storm也是应用了类似的心跳机制来进行检测。<br>例如：所有机器约定在父目录GroupMembers下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除。</p>
<p>新机器加入也是类似，所有机器收到通知：新兄弟目录加入，highcount又有了，对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master就好。<br><img src="../../../../images/zookeeper1.png" alt="sample"></p>
<p>Storm的所有的状态信息都保存在Zookeeper里面，nimbus通过在zookeeper上面写状态信息来分配任务:<br>使得nimbus可以监控整个storm集群的状态，从而可以重启一些挂掉的task。 ZooKeeper使得整个storm集群十分的健壮-—任何一台工作机器挂掉都没有关系，只要重启然后从zookeeper上面重新获取状态信息就可以了<br><img src="../../../../images/zookeeper2.png" alt="sample"></p>
<p>ZooKeeper搭建参考资料：<br><a href="https://blog.csdn.net/qiushisoftware/article/details/79043379" target="_blank" rel="noopener">https://blog.csdn.net/qiushisoftware/article/details/79043379</a><br><a href="https://www.cnblogs.com/felixzh/p/5869212.html" target="_blank" rel="noopener">https://www.cnblogs.com/felixzh/p/5869212.html</a><br><a href="https://blog.csdn.net/xuxiuning/article/details/51218941" target="_blank" rel="noopener">https://blog.csdn.net/xuxiuning/article/details/51218941</a><br><a href="https://blog.csdn.net/shichen2010/article/details/50275473" target="_blank" rel="noopener">https://blog.csdn.net/shichen2010/article/details/50275473</a><br><a href="https://blog.csdn.net/daiyutage/article/details/52049519" target="_blank" rel="noopener">https://blog.csdn.net/daiyutage/article/details/52049519</a><br><a href="https://www.cnblogs.com/hzorac/p/5570721.html" target="_blank" rel="noopener">https://www.cnblogs.com/hzorac/p/5570721.html</a></p>
<h3 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h3><p>Hadoop核心就是HDFS和MapReduce。要想了解Hadoop，就必须知道HDFS和MapReduce是什么。<br>HDFS（HadoopDistributedFileSystem，Hadoop分布式文件系统）<br>它是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，适合那些有着超大数据集（largedataset）的应用程序。<br>HDFS的关键元素：</p>
<p>Block：将一个文件进行分块，通常是64M。</p>
<p>NameNode：保存整个文件系统的目录信息、文件信息及分块信息，这是由唯一一台主机专门保存，当然这台主机如果出错，NameNode就失效了。在Hadoop2.*开始支持activity-standy模式—-如果主NameNode失效，启动备用主机运行NameNode。</p>
<p>DataNode：分布在廉价的计算机上，用于存储Block块文件。<br><img src="../../../../images/hadoop1.png" alt="sample"></p>
<p>MapReduce<br>通俗说MapReduce是一套从海量源数据提取分析元素最后返回结果集的编程模型，将文件分布式存储到硬盘是第一步，然后从海量数据中提取分析。<br>和HDFS一样，MapReduce也是采用Master/Slave的架构，其架构图如下所示：<br><img src="../../../../images/hadoop2.png" alt="sample"></p>
<p>JobTracker：即Master，用于管理所有作业，将作业分解成一系列任务，并将任务指派给TaskTracker，主要用于任务监控，错误处理等。<br>TaskTrackers：Slave，用于运行MapTask和ReduceTask，执行JobTracker命令，汇报任务状态。<br>MapTask：Map引擎，解析每条数据记录，传递给用户编写的map()函数，将map()输出数据写入磁盘或者HDFS<br>ReduceTask:从MapTask上远程读取输入数据，对数据排序，将数据分组传递给用户编写的reduce()</p>
<p>MapResuce运行流程：<br><img src="../../../../images/hadoop3.png" alt="sample"></p>
<p>MapReduce的特点<br>1、易于编程：<br>MapReduce提供了一种抽象机制将程序员与系统层细节隔离开来，程序员仅需描述需要计算什么(whattocompute),而具体怎么去做(howtocompute)就交由系统的执行框架处理，这样程序员可从系统层细节中解放出来，而致力于其应用本身计算问题的算法设计。</p>
<p>例如软件工程实践指南中，专业程序员认为之所以写程序困难，是因为程序员需要记住太多的编程细节(从变量名到复杂算法的边界情况处理)，这对大脑记忆是一个巨大的认知负担,需要高度集中注意力而并行程序编写有更多困难，如需要考虑多线程中诸如同步等复杂繁琐的细节，由于并发执行中的不可预测性，程序的调试查错也十分困难；大规模数据处理时程序员需要考虑诸如数据分布存储管理、数据分发、数据通信和同步、计算结果收集等诸多细节问题。</p>
<p>2、良好的扩展性<br>当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。</p>
<p>3、高容错性:<br>MapReduce设计的初衷就是使程序能够部署在廉价的PC机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上面上运行，不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由Hadoop内部完成的。</p>
<p>4、PB级以上海量数据的离线处理<br>这里加上离线处理，说明它适合离线处理而不适合在线处理。比如像毫秒级别的返回一个结果，MapReduce很难做到。</p>
<p>缺点（不善长方面）：<br>1、实时计算<br>像MySQL一样，在毫秒级或者秒级内返回结果</p>
<p>2、流式计算<br>MapReduce的输入数据集是静态的，不能动态变化<br>MapReduce自身的设计特点决定了数据源必须是静态的</p>
<p>3、DAG计算<br>多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出<br>也就是说用MapReduce来处理的数据集（或任务）必须具备这样的特点：<br>待处理的数据集可以分解成许多小的数据集，而且每一个小数据集都可以完全并行地进行处理。</p>
<p>简单了解，主要看spark,storm等现阶段实时性较高的分布式计算框架。<br>参考资料：<br><a href="http://hadoop.apache.org/" target="_blank" rel="noopener">http://hadoop.apache.org/</a><br><a href="https://blog.csdn.net/zhangliangzi/article/details/52071218" target="_blank" rel="noopener">https://blog.csdn.net/zhangliangzi/article/details/52071218</a><br><a href="https://blog.csdn.net/u013850277/article/details/59792145" target="_blank" rel="noopener">https://blog.csdn.net/u013850277/article/details/59792145</a><br><a href="https://blog.csdn.net/jiangyu1013/article/details/72644098" target="_blank" rel="noopener">https://blog.csdn.net/jiangyu1013/article/details/72644098</a><br><a href="https://blog.csdn.net/yywusuoweile/article/details/47678897" target="_blank" rel="noopener">https://blog.csdn.net/yywusuoweile/article/details/47678897</a><br><a href="https://www.zhihu.com/search?q=hadoop&amp;type=content" target="_blank" rel="noopener">https://www.zhihu.com/search?q=hadoop&amp;type=content</a></p>
<h3 id="再来看看spark"><a href="#再来看看spark" class="headerlink" title="再来看看spark"></a>再来看看spark</h3><h4 id="1-1什么是Spark"><a href="#1-1什么是Spark" class="headerlink" title="1.1什么是Spark?"></a>1.1什么是Spark?</h4><p>ApacheSpark则是UCBerkeleyAMPlab(加州大学伯克利分校AMP实验室)所开源的类HadoopMapReduce的通用并行框架,专门用于大数据量下的迭代式计算</p>
<h4 id="1-2Spark比Hadoop对比"><a href="#1-2Spark比Hadoop对比" class="headerlink" title="1.2Spark比Hadoop对比"></a>1.2Spark比Hadoop对比</h4><p>Spark开发是为了跟Hadoop配合的,不是为了取代Hadoop,Spark运算比Hadoop的MapReduce框架快的原因是因为Hadoop在一次Map运算之后,会将数据的运算结果从内存写入到磁盘中,第二次Reduce运算时在从磁盘中读取数据,所以其瓶颈在2次运算间的多余IO消耗.Spark将数据一直缓存在内存中,直到计算得到最后的结果,再将结果写入到磁盘,所以多次运算的情况下,Spark是比较快的.其优化了迭代式工作负载.</p>
<p>在网上有找到这样的对比总结：<br><img src="../../../../images/spark1.png" alt="sample"><br>Spark的主要特点还包括:<br>(1)提供Cache机制来支持需要反复迭代计算或者多次数据共享,减少数据读取的IO开销;<br>(2)提供了一套支持DAG图的分布式并行计算的编程框架,减少多次计算之间中间结果写到Hdfs的开销;<br>(3)使用多线程池模型减少Task启动开稍,shuffle过程中避免不必要的sort操作并减少磁盘IO操作。(Hadoop的Map和reduce之间的shuffle需要sort)<br>通过以上几个点看出，其实和storm进行对比分析，相同点是<strong>都是使用了DAG，并且可以反复迭代计算，都可以启用多进程进而建立多线程进行并行运算，但是storm因为是流式计算不能存储中间结果，需要一些消息中间件来配合使用。具体操作，感觉应该看看sparkstreaming和storm的区别</strong></p>
<p>spark生态系统可以分为以下几个部分：<br><img src="../../../../images/spark2.png" alt="sample"></p>
<p>-SparkSQL:提供了类SQL的查询,返回Spark-DataFrame的数据结构(类似Hive)<br>-SparkStreaming:流式计算,主要用于处理线上实时时序数据(类似storm)<br>-MLlib:提供机器学习的各种模型和调优<br>-GraphX:提供基于图的算法,如PageRank</p>
<p>Spark系统架构：<br>1.应用程序(Application):基于Spark的用户程序，包含了一个DriverProgram和集群中多个的Executor；<br>2.驱动(Driver):运行Application的main()函数并且创建SparkContext;<br>3.执行单元(Executor):是为某Application运行在WorkerNode上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上，每个Application都有各自独立的Executors;<br>4.集群管理程序(ClusterManager):在集群上获取资源的外部服务(例如：Local、Standalone、Mesos或Yarn等集群管理系统)；<br>5.操作(Operation):作用于RDD的各种操作分为Transformation和Action.</p>
<p><img src="../../../../images/spark3.png" alt="sample"></p>
<p>整个Spark集群中,分为Master节点与worker节点,,其中Master节点上常驻Master守护进程和Driver进程,Master负责将串行任务变成可并行执行的任务集Tasks,同时还负责出错问题处理等,而Worker节点上常驻Worker守护进程,Master节点与Worker节点分工不同,Master负载管理全部的Worker节点,而Worker节点负责执行任务.<br>Driver的功能是创建SparkContext,负责执行用户写的Application的main函数进程,Application就是用户写的程序.<br>Spark支持不同的运行模式,包括Local,Standalone,Mesoses,Yarn模式.不同的模式可能会将Driver调度到不同的节点上执行.集群管理模式里,local一般用于本地调试.<br>每个Worker上存在一个或多个Executor进程,该对象拥有一个线程池,每个线程负责一个Task任务的执行.根据Executor上CPU-core的数量,其每个时间可以并行多个跟core一样数量的Task.Task任务即为具体执行的Spark程序的任务.</p>
<p>Spark运行原理（帮助理解）：<br>使用spark-submit提交一个Spark作业之后，这个作业就会启动一个对应的Driver进程。根据你使用的部署模式（deploy-mode）不同，Driver进程可能在本地启动，也可能在集群中某个工作节点上启动。而Driver进程要做的第一件事情，就是向集群管理器（可以是SparkStandalone集群，也可以是其他的资源管理集群，美团•大众点评使用的是YARN作为资源管理集群）申请运行Spark作业需要使用的资源，这里的资源指的就是Executor进程。YARN集群管理器会根据我们为Spark作业设置的资源参数，在各个工作节点上，启动一定数量的Executor进程，每个Executor进程都占有一定数量的内存和CPUcore。<br>　　在申请到了作业执行所需的资源之后，Driver进程就会开始调度和执行我们编写的作业代码了。Driver进程会将我们编写的Spark作业代码分拆为多个stage，每个stage执行一部分代码片段，并为每个stage创建一批Task，然后将这些Task分配到各个Executor进程中执行。Task是最小的计算单元，负责执行一模一样的计算逻辑（也就是我们自己编写的某个代码片段），只是每个Task处理的数据不同而已。一个stage的所有Task都执行完毕之后，会在各个节点本地的磁盘文件中写入计算中间结果，然后Driver就会调度运行下一个stage。下一个stage的Task的输入数据就是上一个stage输出的中间结果。如此循环往复，直到将我们自己编写的代码逻辑全部执行完，并且计算完所有的数据，得到我们想要的结果为止。<br><strong>从整个运行原理可以看出，为什么说storm是实时的，而spark不是实时的，因为spark steaming在划分stage时，中间其实有一个IO的操作，尽管是内存读取很快，但是也是有时间的消耗，但这样有一个好处就是可以随时获取中间结果，并且我感觉原理上应该是可以在运行过程中动态调整执行的运算</strong></p>
<p>RDD(ResilentDistributedDatasets)弹性分布式数据集：<br>Spark底层的分布式存储的数据结构,可以说是Spark的核心,SparkAPI的所有操作都是基于RDD的.数据不只存储在一台机器上,而是分布在多台机器上,实现数据计算的并行化.弹性表明数据丢失时,可以进行重建。RDD 是一种只读的数据块,可以从外部数据转换而来,可以对RDD 进行函数操作(Operation),包括 Transformation 和 Action。Transformation 操作不是马上提交 Spark 集群执行的,Spark 在遇到 Transformation 操作时只会记录需要这样的操作,并不会去执行,需要等到有 Action 操作的时候才会真正启动计算过程进行计算.针对每个 Action,Spark 会生成一个 Job, 从数据的创建开始,经过 Transformation, 结尾是 Action 操作.这些操作对应形成一个有向无环图(DAG),形成 DAG 的先决条件是最后的函数操作是一个Action.</p>
<p><img src="../../../../images/spark4.png" alt="sample"></p>
<p><strong>这里面有挺多操作类似于join,groupBy都是spark已经封装好的，可以直接用，但是在storm里面据我所知没有，需要自己去定义这样的操作，spark除了这些内置函数之外，可以自己定义一些操作么？</strong></p>
<p>spark里面有很多运算调优的操作，例如使用线程池减少线程切换的时间，内存优化（storm里面应该也有），负载均衡之类的。</p>
<h3 id="Spark和Storm之间的对比"><a href="#Spark和Storm之间的对比" class="headerlink" title="Spark和Storm之间的对比"></a>Spark和Storm之间的对比</h3><table>
<thead>
<tr>
<th>对比点</th>
<th style="text-align:center">Storm</th>
<th style="text-align:center">Spark </th>
</tr>
</thead>
<tbody>
<tr>
<td>实时计算模型</td>
<td style="text-align:center">实时，来一条数据，处理一条数据</td>
<td style="text-align:center">准实时，对一个时间段内的数据收集起来，作为一个RDD，再处理</td>
</tr>
<tr>
<td>实时计算延迟度</td>
<td style="text-align:center">毫秒级</td>
<td style="text-align:center">秒级</td>
</tr>
<tr>
<td>吞吐量</td>
<td style="text-align:center">低</td>
<td style="text-align:center">高</td>
</tr>
<tr>
<td>事务机制</td>
<td style="text-align:center">支持完善</td>
<td style="text-align:center">支持，但不够完善</td>
</tr>
<tr>
<td>健壮性 / 容错性</td>
<td style="text-align:center">ZooKeeper，Acker，非常强</td>
<td style="text-align:center">Checkpoint，WAL，一般</td>
</tr>
<tr>
<td>动态调整并行度</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">不支持</td>
</tr>
<tr>
<td>易用性</td>
<td style="text-align:center">支持SQL Streaming，Batch采用统一编程框架</td>
<td style="text-align:center">不支持SQL Streaming</td>
</tr>
</tbody>
</table>
<p>Spark还有挺多优化的操作，拥有整个Spark生态，相对storm来说可能更加全面，在上面分析spark的操作时也是有进行storm的一些对比（自己理解，可能有误。。。）</p>
<p>参考资料：<br><a href="http://spark.apache.org/documentation.html" target="_blank" rel="noopener">http://spark.apache.org/documentation.html</a><br><a href="https://blog.csdn.net/yangbutao/article/details/44538637" target="_blank" rel="noopener">https://blog.csdn.net/yangbutao/article/details/44538637</a><br><a href="https://blog.csdn.net/u012721013/article/details/53424638" target="_blank" rel="noopener">https://blog.csdn.net/u012721013/article/details/53424638</a><br><a href="https://zhuanlan.zhihu.com/p/34436165" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/34436165</a><br><a href="https://www.cnblogs.com/yaohaitao/p/5703288.html" target="_blank" rel="noopener">https://www.cnblogs.com/yaohaitao/p/5703288.html</a><br><a href="https://zhuanlan.zhihu.com/p/36024639" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/36024639</a><br><a href="https://www.cnblogs.com/snowbook/p/5773562.html" target="_blank" rel="noopener">https://www.cnblogs.com/snowbook/p/5773562.html</a></p>
<h3 id="openshift"><a href="#openshift" class="headerlink" title="openshift"></a>openshift</h3><p>OpenShift是由红帽推出逇一款面向开源开发人员开放的平台即服务(PaaS将服务器平台或者开发环境作为服务)。OpenShift通过为开发人员提供在语言、框架和云上的更多的选择，使开发人员可以构建、测试、运行和管理他们的应用。它支持用于Java、Python、PHP、Perl和Ruby的更多的开发框架，包括Spring、Seam、Weld、CDI、Rails、Rack、Symfony、ZendFramework、Twisted、Django和JavaE。它包含SQL和NoSQL数据存储和一个分布式文件系统。其实对比分布式计算要解决的问题以及场景，openshift跟分布式计算都没有什么关系，我觉得它适用于app的分布式部署，不涉及计算，也不涉及mapReduce的过程。但是还是根据资料，记录一下，也许以后用得到。。。<br>openShift部署过程支持依靠Git，jenkins，Maven等标准开源部署工具，集成在IDE中进行代码上传部署。RedHat给每个用户三枚免费的Gear,可以用Gear运行你的应用。每个用户能免费使用总共1.5GB内存和3GB硬盘空间。<br>OpenShift容器平台有一个基于微服务的架构，它是一个小型的、解耦的单元，可以协同工作。它运行在Kubernetes集群的顶部，有关于存储在etcd中的对象的数据，这是一个可靠的集群键值存储。这些服务被功能分解了:</p>
<p>1.RESTapi，它公开了每个核心对象。<br>2.控制器读取这些api，对其他对象应用更改，并报告状态或写回对象。</p>
<p>用户对RESTAPI进行调用，以更改系统的状态。控制器使用RESTAPI来读取用户想要的状态，然后尝试将系统的其他部分进行同步。例如，当用户请求一个构建时，他们会创建一个“构建”对象。构建控制器看到已经创建了一个新的构建，并在集群上运行一个进程来执行该构建。当构建完成时，控制器将通过RESTAPI更新构建对象，用户看到他们的构建完成了。</p>
<p>现如今，openShift大多数都结合docker进行配合使用。</p>
<p>自动构建和部署应用：这怎么实现（<a href="https://blog.csdn.net/wjs7740/article/details/75215231）" target="_blank" rel="noopener">https://blog.csdn.net/wjs7740/article/details/75215231）</a><br>OpenShiftV3提供了3种来自动构建应用的方法。<br>Docker-File模式：通过向OpenShift提供指向Docker-File以及其依附关系的源码管理器的URI来自动构建一个Docker容器。<br><img src="../../../../images/openshift1.png" alt="sample"><br>Source-To-Image模式（STI）：允许通过提交应用的源码到OpenShift来自动构建一个应用。（就像Heroku中的buildpacks）。<br><img src="../../../../images/openshift2.png" alt="sample"><br>自定义构建模式：允许提供自己的应用来构建逻辑，这是通过提供一个OpenShiftDocker的镜像实现的。<br><img src="../../../../images/openshift3.png" alt="sample"></p>
<p>没有看太懂其中逻辑，不过可以确定的是三种都是转化为docker镜像进行部署（如果深入了解，需要看看docker内部实现）。</p>
<p>关于部署的过程，可以参考<br>（<a href="https://blog.csdn.net/judyge/article/details/52176082和https://blog.csdn.net/hao707822882/article/details/38872279）" target="_blank" rel="noopener">https://blog.csdn.net/judyge/article/details/52176082和https://blog.csdn.net/hao707822882/article/details/38872279）</a><br>官网：<a href="https://www.openshift.com/products" target="_blank" rel="noopener">https://www.openshift.com/products</a></p>
<h3 id="Hadoop、spark、storm、SaaS、PaaS、IaaS、云计算概念区分？"><a href="#Hadoop、spark、storm、SaaS、PaaS、IaaS、云计算概念区分？" class="headerlink" title="Hadoop、spark、storm、SaaS、PaaS、IaaS、云计算概念区分？"></a>Hadoop、spark、storm、SaaS、PaaS、IaaS、云计算概念区分？</h3><p>首先要分为两组</p>
<p>1.hadoop,spark,storm<br>2.SaaS,PaaS,IaaS</p>
<p>第一组：分布式计算框架，当前很多大数据平台是基于hadoop的。对于spark是对于hadoop的一个质的变化，即可以替代hadoop中的mapreduce+hive的部分功能，同时由于大量操作基于内存计算和处理获得更高的性能，storm是更加实时的分布式计算框架。</p>
<p>第二组：<br>IaaS：基础设施服务，Infrastructure-as-a-service 是软件的开发、管理、部署都交给第三方，不需要关心技术问题，可以拿来即用。普通用户接触到的互联网服务，几乎都是 SaaS<br>PaaS：平台服务，Platform-as-a-service 提供软件部署平台（runtime），抽象掉了硬件和操作系统细节，可以无缝地扩展（scaling）。开发者只需要关注自己的业务逻辑，不需要关注底层 即OpenShift等一类平台提供的服务<br>SaaS：软件服务，Software-as-a-service 云服务的最底层，主要提供一些基础资源。它与 PaaS 的区别是，用户需要自己控制底层，实现基础设施的使用逻辑。<br>（<a href="http://www.ruanyifeng.com/blog/2017/07/iaas-paas-saas.html）" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2017/07/iaas-paas-saas.html）</a><br>这一组是标准的云计算三层，判断是否是云计算平台的核心即是否是在原来终端的能力，不论是存储还是计算，还是平台或应用层能力，统一迁移到了统一的云端，并通过服务化的方式暴露出来，如果是，符合云的第一基础特征。如何该平台本身是能够弹性扩展和伸缩的，则符合云的第二个核心特征，其余的按需使用和计费等都不是重点。<br>因此可知，1和2两组之间可能有融合，也可能完全没有任何关系。<br>比如你现在为了处理内部的一个科学计算需求，搭建了一个hadoop平台基于map-reduce进行并行计算和处理，那么仅仅是实现了并行计算。即使你搭建hadoop的时候在内部使用了大量的虚拟机，本身也和云计算没半点关系。如果你搭建了一个平台，这个平台可以为所有有类似科学计算需求的人服务，那么这个平台可以算做云平台，如果这个平台本身还可以随时用户的增加动态弹性扩展底层资源那么是一个完整的云计算平台。而这个平台可能并不需要用hadoop技术来实现并行计算，那么它也是一个云平台，只是没有使用hadoop技术而已。</p>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'http-miccall-tech'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://yoursite.com/2018/06/17/openshift/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://yoursite.com/2018/06/17/openshift/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//http-miccall-tech.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Design: <a href="http://miccall.tech " style="border-bottom: none;">miccall</a></li>
            </ul>
            
            	<span id="busuanzi_container_site_pv">2018总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
</body>



 	
</html>
<script type="text/javascript" src="/js/love.js"></script>
