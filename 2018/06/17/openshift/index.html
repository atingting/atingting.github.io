<!DOCTYPE HTML>
<html>

<head>
	<link rel="bookmark"  type="image/x-icon"  href="/img/logo_miccall.png"/>
	<link rel="shortcut icon" href="/img/logo_miccall.png">
	
			    <title>
    Fairyting's blog
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    <meta name="keywords" content="miccall" />
    
    	<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/bg.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
</head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">Ting</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">主页</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/about/" title="简历">
		                简历
		            </a>
		        </li>
		        
		        <li>
		            <a href="/gallery/" title="生活">
		                生活
		            </a>
		        </li>
		        
		        <li>
		            <a href="/material/" title="学习资料">
		                学习资料
		            </a>
		        </li>
		        
		        <li>
		            <a href="/learning/" title="Mark">
		                Mark
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
		            
		                <li><a href="https://github.com/atingting" class="icon fa-github"><span class="label">GitHub</span></a></li>
		            
		            
		            
		            
		                <li><a href="mailto:zhangtingting.code@gmail.com" class="icon fa-envelope"><span class="label">Envelope</span></a></li>
		            
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img" style="height: 25rem;background-image: url(/images/distribute.png);background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2 >分布式计算</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <p>最近要做一些分布式计算框架的调研，来记录一下看的东西，以免忘记：</p>
<h3 id="1-什么是分布式计算"><a href="#1-什么是分布式计算" class="headerlink" title="1.什么是分布式计算"></a><strong>1.什么是分布式计算</strong></h3><p>分布式计算简单来说，是把一个大计算任务拆分成多个小计算任务分布到若干台机器上去计算，然后再进行结果汇总，目的在于分析计算海量的数据。海量计算最开始的方案是提高单机计算性能，如大型机，后来由于数据的爆发式增长、单机性能却跟不上，才有分布式计算这种妥协方案。 因为计算一旦拆分，问题会变得非常复杂，像一致性、数据完整、通信、容灾、任务调度等问题也都来了。<br>举个例子，产品要求从数据库中100G的用户购买数据，分析出各地域的消费习惯金额等。 如果没什么时间要求，通常我们就写个对应的业务处理服务程序，部署到服务器上，让它慢慢跑就是了，我们预计10个小时能处理完。 但是后面客户嫌太慢，让想办法加快到半个小时，因此分布式计算产生了，平常开发中类似的需求也很多，总结出来就是，数据量大、单机计算慢，因此我们转向使用多台机器进行运算，现如今分布式计算框架主要有spark,storm,hadoop,AKKA.openshift不知道能不能做分布式，记忆中是结合docker用来做程序部署的.  </p>
<h3 id="先看看storm"><a href="#先看看storm" class="headerlink" title="先看看storm:"></a>先看看storm:</h3><p>Apache Storm 是由Twitter开源的分布式实时计算系统。Storm可以非常容易并且可靠的处理无限的数据流。对比Hadoop的批处理，Storm是一个实时的、分布式的、具备高容错的计算系统。Storm应用可以使用不同的编程语言来进行开发。<br>具有如下好处：<br>易于扩展。对于扩展，你只需要添加机器和改变对应的topology（拓扑）设置。Storm使用Hadoop Zookeeper进行集群协调，这样可以充分的保证大型集群的良好运行。<br>1.每条信息的处理都可以得到保证。<br>2.Storm集群管理简易。<br>3.Storm的容错机能：一旦topology递交，Storm会一直运行它直到topology被废除或者被关闭。而在执行中出现错误时，也会由Storm重新分配任务。<br>4.尽管通常使用Java，Storm中的topology可以用任何语言设计。<br><img src="../../../../images/distribute1.png" alt="sample"><br>Nimbus和Supervisor之间的通信依靠Zookeeper来完成，并且Nimbus进程和Supervisor都是快速失败和无状态的.我的理解是如果挂了可以重启，它们可以继续工作。<br>storm里面有一些核心基本概念：包括Topology、Nimbus、Supervisor、Worker、Executor、Task、Spout、Bolt、Tuple、Stream、Stream分组（grouping）等。<br>Topology：  一个实时计算应用程序逻辑上被封装在Topology对象中，类似Hadoop中的作业。与作业不同的是，Topology会一直运行直到显式地杀死它。<br>Nimbus：  负责资源分配和任务调度。<br>Supervisor：  负责接受Nimbus分配的任务，启动和停止属于自己管理的Worker进程。<br>Worker：  运行具体处理组件逻辑的进程。<br>Executor：  Storm 0.8之后，Executor为Worker进程中的具体的物理线程，同一个Spout/Bolt的Task可能会共享一个物理线程，一个Executor中只能运行隶属于同一个Spout/Bolt的Task。<br>Task：  每一个Spout/Bolt具体要做的工作，也是各个节点之间进行分组的单位。<br>Spout：  在Topology中产生源数据流的组件。通常Spout获取数据源的数据，然后调用nextTuple函数，发射数据供Bolt消费。<br>Bolt：  在Topology中接受Spout的数据然后执行处理的组件，Bolt可以执行过滤，函数操作，合并，写数据库等任何操作。Bolt在接收到消息后会调用execute函数，用户可在其中执行自己想要的操作，bolt 可以订阅多个由 spout 或者其他bolt 发射的数据流，这样就可以建立复杂的数据流转换网络。<br>Tuple：  消息传递的单元。<br>Stream：  源源不断传递的Tuple组成了Stream。<br>Stream分组：  即消息的分区（partition）方法。Storm中提供若干种实用的分组方式。包括Shuffle、Fields、All、Global、None、Direct、Local or shuffle等。<br>Storm有7种内置的分组方式，也可以通过实现CustomStreamGrouping接口来定义自己的分组。</p>
<p>（1）Shuffle分组：Task中的数据随机分配，可以保证同一级Bolt上的每个Task处理的Tuple数量一致。</p>
<p>（2）Fields分组：  根据Tuple中的某一个Filed或者多个Filed的值来划分。比如Stream根据user-id的值来分组，具有相同的user-id值的Tuple会被分发到相同的Task中。</p>
<p>（3）All分组：        所有的Tuple都会分发到所有的Task上。</p>
<p>（4）Global分组：  整个Stream会选择一个Task作为分发的目的地，通常是具有最新ID的Task。</p>
<p>（5）None分组：    也就是你不关心如何在Task中做Stream的分发，目前等同于Shuffle分组。</p>
<p>（6）Direct分组：   这是一种特殊的分组方式，也就是产生数据的Spout/Bolt自己明确决定这个Tuple被Bolt的哪些Task所消费。如果Direct分组，需要使用OutputCollector的emitDirect方法来实现。</p>
<p>（7）Local or shuffle分组：如果目标Bolt中的一个或者多个Task和当前产生数据的Task在同一个Worker进程中，那么就走内部的线程间通信，将Tuple直接发给在当前Worker进程中的目的Task。否则，同Shuffle分组<br>storm运行的数据流转换网络Topology可以如下图进行理解：<br><img src="../../../../images/distribute3.png" alt="sample"><br>Topology：在这个Topology中，我们看到Spout和Bolt。在Topology中，我们将Spout和Bolt称之为组件(Components)。一个Topology中，必须同时存在Spout和Bolt，Spout和Bolt数量可以随意，Topology的组件目前只有Spout和Bolt，没有其他组件。  </p>
<p>Stream：我们已经知道Spout是从外部数据源中获取数据，以一定的格式将数据传递给Bolt处理。从Spout中源源不断的给Bolt传递数据，形成的这个数据通道我们称之为Stream(流)。因为Strom是一个实时计算的流式处理框架，其不是像hadoop那样，一次性处理一大批的数据(批处理)，以及spark一次性处理一个batch的数据，Storm是不断从外部数据源中获取最新的数据，然后将新的数据传递给Bolt处理(增量处理)。这样不断的获取与传输就形成了这个数据流通道就称之为Stream，因此实时性很高。而Stream传输的最小单位Tuple是有数据格式的，在同一个流中,Tuple的数据格式应该都是一样的；不同流中的数据格式可能相同，也可能不同。  </p>
<p>DAG(有向无环图): 在storm中，spout和bolt、bolt与bolt之间的数据流向，将整合topology串起来了。topology是DAG即有向无环图，意思就是数据流是有方向的，但是不能形成一个环状。如果形成了一个环状，那么意味着Bolt中的数据还可能传给Spout，spout又要传递给Bolt。这就形成了一个死循环，Stream中的一个数据(Tuple)永远也没办法处理完。</p>
<p>以上看出storm的一些特性，其中实时性很高决定了我们不能选用一般的例如数据库直接读取等数据源，关于数据源的选择：<br>1、实时性<br>Storm是一个实时计算框架。其不能一次性获取所有的数据，进行分析处理。而是Spout不断的从外部数据源中获取最新的数据，然后交给Bolt处理。这意味着，Spout必须要不断的检测外部数据源有没有最新的数据，如果有新数据了，就获取到最新的数据，然后交给Bolt处理。<br>2、容错<br>而且还必须要考虑的是，如果一条数据处理失败了，Spout必须还能再次获取这条数据，否则计算出的结果的误差就会比较大。<br>3、数据路由<br>同时一个Topology中可能会有多个Spout来从外部数据源中获取数据，假设我们有SPOUTA、SPOUTB、SPOUTC，那么某些业务场景下，我们可能希望同一条数据，SPOUTA、SPOUTB、SPOUTC都能获取到。在另外一些业务场景下，可能只希望SPOUTA获取到这条数据。如果数据源不支持路由，意味着，对于不同Topology，需要开发不同的数据获取机制。</p>
<p>而对于这些需求，现有的JMS消息机制，可以满足这个条件。主流的消息中间件，如Kafka、RocketMq等。 因此如果要使用strom，需要配合消息中间件使用。</p>
<p>Storm的容错机制<br>1 Worker进程死亡<br>当仅有Worker进程死亡时，其主机上的Supervisor会尝试重启Worker进程，如果连续重启都失败，当超过一定的失败次数之后，Nimbus会在其他主机上重启Worker。</p>
<p>当Supervisor死亡时，如果某个主机上的Worker死亡了，由于没有Supervisor，所以无法在本机重启Worker，但会在其他主机上重启Worker，当Supervisor重启以后，会将本机的Worker重启，而之间在其他主机上重启的Worker则会消失，例如之前node2有三个Worker，node3有三个Worker，当node2的Supervisor死亡并且kill掉一个Worker之后，node3出现四个Worker，重启node2的Supervisor之后，node2会重启一个Worker，恢复成三个Worker，node3kill掉多余的一个Worker，也恢复成三个Worker。</p>
<p>当Nimbus死亡时，Worker也会继续执行，但是某个Worker死亡时不会像Supervisor死亡时安排到其他主机上执行，因此如果Worker全部死亡，则任务执行失败。</p>
<p>集群中的Worker是均匀分配到各节点上的，例如一个作业有三个Worker时，会在一个节点（例如node2）分配两个Worker，在一个节点（例如node3）分配一个Worker，当再启动一个需要三个Worker的作业时，会在node2分配一个Worker，在node3分配两个Worker。</p>
<p>2 Nimbus或者Supervisor进程死亡<br>Nimbus和Supervisor被设计成是快速失败且无状态的，他们的状态都保存在ZooKeeper或者磁盘上，如果这两个进程死亡，它们不会像Worker一样自动重启，但是集群上的作业仍然可以在Worker中运行，并且他们重启之后会像什么都没发生一样正常工作。</p>
<p>3 ZooKeeper停止<br>ZooKeeper的停止同样不会影响已有的作业运行，此时kill掉Worker以后过段时间仍会在本机重启一个Worker。</p>
<p>综上所述，只有Nimbus失败并且所有Worker都失败之后才会影响集群上的作业运行，除此之外Storm集群的容错机制可以保证作业运行的可靠性。</p>
<p>对于storm的理解，在网上找了一个例子，用storm来进行分词，代码如下（亲测可运行）：</p>
<p>新建类SentenceSpout.java（数据流生成者）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line">import org.apache.storm.spout.SpoutOutputCollector;</span><br><span class="line">import org.apache.storm.task.TopologyContext;</span><br><span class="line">import org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line">import org.apache.storm.topology.base.BaseRichSpout;</span><br><span class="line">import org.apache.storm.tuple.Fields;</span><br><span class="line">import org.apache.storm.tuple.Values;</span><br><span class="line">import org.apache.storm.utils.Utils;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 向后端发射tuple数据流</span><br><span class="line"> * @author soul</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public class SentenceSpout extends BaseRichSpout &#123;</span><br><span class="line"></span><br><span class="line">    //BaseRichSpout是ISpout接口和IComponent接口的简单实现，接口对用不到的方法提供了默认的实现</span><br><span class="line"></span><br><span class="line">    private SpoutOutputCollector collector;</span><br><span class="line">    private String[] sentences = &#123;</span><br><span class="line">            &quot;my name is soul&quot;,</span><br><span class="line">            &quot;im a boy&quot;,</span><br><span class="line">            &quot;i have a dog&quot;,</span><br><span class="line">            &quot;my dog has fleas&quot;,</span><br><span class="line">            &quot;my girl friend is beautiful&quot;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    private int index=0;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * open()方法中是ISpout接口中定义，在Spout组件初始化时被调用。</span><br><span class="line">     * open()接受三个参数:一个包含Storm配置的Map,一个TopologyContext对象，</span><br><span class="line">     提供了topology中组件的信息,SpoutOutputCollector对象提供发射tuple的方法。</span><br><span class="line">     * 在这个例子中,我们不需要执行初始化,只是简单的存储在一个SpoutOutputCollector实例变量。</span><br><span class="line">     */</span><br><span class="line">    public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) &#123;</span><br><span class="line">        // TODO Auto-generated method stub</span><br><span class="line">        this.collector = collector;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * nextTuple()方法是任何Spout实现的核心。</span><br><span class="line">     * Storm调用这个方法，向输出的collector发出tuple。</span><br><span class="line">     * 在这里,我们只是发出当前索引的句子，并增加该索引准备发射下一个句子。</span><br><span class="line">     */</span><br><span class="line">    public void nextTuple() &#123;</span><br><span class="line">        //collector.emit(new Values(&quot;hello world this is a test&quot;));</span><br><span class="line"></span><br><span class="line">        // TODO Auto-generated method stub</span><br><span class="line">        this.collector.emit(new Values(sentences[index]));</span><br><span class="line">        index++;</span><br><span class="line">        if (index&gt;=sentences.length) &#123;</span><br><span class="line">            index=0;</span><br><span class="line">        &#125;</span><br><span class="line">        Utils.sleep(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * declareOutputFields是在IComponent接口中定义的，所有Storm的组件（spout和bolt）都必须实现这个接口</span><br><span class="line">     * 用于告诉Storm流组件将会发出那些数据流，每个流的tuple将包含的字段</span><br><span class="line">     */</span><br><span class="line">    public void declareOutputFields(OutputFieldsDeclarer declarer) &#123;</span><br><span class="line">        // TODO Auto-generated method stub</span><br><span class="line"></span><br><span class="line">        declarer.declare(new Fields(&quot;sentence&quot;));//告诉组件发出数据流包含sentence字段</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>新建类SplitSentenceBolt.java（单词分割器）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line">import org.apache.storm.task.OutputCollector;</span><br><span class="line">import org.apache.storm.task.TopologyContext;</span><br><span class="line">import org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line">import org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line">import org.apache.storm.tuple.Fields;</span><br><span class="line">import org.apache.storm.tuple.Tuple;</span><br><span class="line">import org.apache.storm.tuple.Values;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 订阅sentence spout发射的tuple流，实现分割单词</span><br><span class="line"> * @author soul</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public class SplitSentenceBolt extends BaseRichBolt &#123;</span><br><span class="line">    //BaseRichBolt是IComponent和IBolt接口的实现</span><br><span class="line">    //继承这个类，就不用去实现本例不关心的方法</span><br><span class="line"></span><br><span class="line">    private OutputCollector collector;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * prepare()方法类似于ISpout 的open()方法。</span><br><span class="line">     * 这个方法在blot初始化时调用，可以用来准备bolt用到的资源,比如数据库连接。</span><br><span class="line">     * 本例子和SentenceSpout类一样,SplitSentenceBolt类不需要太多额外的初始化,</span><br><span class="line">     * 所以prepare()方法只保存OutputCollector对象的引用。</span><br><span class="line">     */</span><br><span class="line">    public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) &#123;</span><br><span class="line">        // TODO Auto-generated method stub</span><br><span class="line">        this.collector=collector;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * SplitSentenceBolt核心功能是在类IBolt定义execute()方法，这个方法是IBolt接口中定义。</span><br><span class="line">     * 每次Bolt从流接收一个订阅的tuple，都会调用这个方法。</span><br><span class="line">     * 本例中,收到的元组中查找“sentence”的值,</span><br><span class="line">     * 并将该值拆分成单个的词,然后按单词发出新的tuple。</span><br><span class="line">     */</span><br><span class="line">    public void execute(Tuple input) &#123;</span><br><span class="line">        // TODO Auto-generated method stub</span><br><span class="line">        String sentence = input.getStringByField(&quot;sentence&quot;);</span><br><span class="line">        String[] words = sentence.split(&quot; &quot;);</span><br><span class="line">        for (String word : words) &#123;</span><br><span class="line">            this.collector.emit(new Values(word));//向下一个bolt发射数据</span><br><span class="line">        &#125;       </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * plitSentenceBolt类定义一个元组流,每个包含一个字段(“word”)。</span><br><span class="line">     */</span><br><span class="line">    public void declareOutputFields(OutputFieldsDeclarer declarer) &#123;</span><br><span class="line">        // TODO Auto-generated method stub</span><br><span class="line">        declarer.declare(new Fields(&quot;word&quot;));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>新建类WordCountBolt.java（单词计数器）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">import java.util.HashMap;</span><br><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line">import org.apache.storm.task.OutputCollector;</span><br><span class="line">import org.apache.storm.task.TopologyContext;</span><br><span class="line">import org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line">import org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line">import org.apache.storm.tuple.Fields;</span><br><span class="line">import org.apache.storm.tuple.Tuple;</span><br><span class="line">import org.apache.storm.tuple.Values;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 订阅 split sentence bolt的输出流，实现单词计数，并发送当前计数给下一个bolt</span><br><span class="line"> * @author soul</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public class WordCountBolt extends BaseRichBolt &#123;</span><br><span class="line">    private OutputCollector collector;</span><br><span class="line">    //存储单词和对应的计数</span><br><span class="line">    private HashMap&lt;String, Long&gt; counts = null;//注：不可序列化对象需在prepare中实例化</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 大部分实例变量通常是在prepare()中进行实例化，这个设计模式是由topology的部署方式决定的</span><br><span class="line">     * 因为在部署拓扑时,组件spout和bolt是在网络上发送的序列化的实例变量。</span><br><span class="line">     * 如果spout或bolt有任何non-serializable实例变量在序列化之前被实例化(例如,在构造函数中创建)</span><br><span class="line">     * 会抛出NotSerializableException并且拓扑将无法发布。</span><br><span class="line">     * 本例中因为HashMap 是可序列化的,所以可以安全地在构造函数中实例化。</span><br><span class="line">     * 但是，通常情况下最好是在构造函数中对基本数据类型和可序列化的对象进行复制和实例化</span><br><span class="line">     * 而在prepare()方法中对不可序列化的对象进行实例化。</span><br><span class="line">     */</span><br><span class="line">    public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) &#123;</span><br><span class="line">        // TODO Auto-generated method stub</span><br><span class="line">        this.collector = collector;</span><br><span class="line">        this.counts = new HashMap&lt;String, Long&gt;();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 在execute()方法中,我们查找的收到的单词的计数(如果不存在，初始化为0)</span><br><span class="line">     * 然后增加计数并存储,发出一个新的词和当前计数组成的二元组。</span><br><span class="line">     * 发射计数作为流允许拓扑的其他bolt订阅和执行额外的处理。</span><br><span class="line">     */</span><br><span class="line">    public void execute(Tuple input) &#123;</span><br><span class="line">        // TODO Auto-generated method stub</span><br><span class="line"></span><br><span class="line">        String word = input.getStringByField(&quot;word&quot;);</span><br><span class="line">        Long count = this.counts.get(word);</span><br><span class="line">        if (count == null) &#123;</span><br><span class="line">            count = 0L;//如果不存在，初始化为0</span><br><span class="line">        &#125;</span><br><span class="line">        count++;//增加计数</span><br><span class="line">        this.counts.put(word, count);//存储计数</span><br><span class="line">        this.collector.emit(new Values(word,count));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * </span><br><span class="line">     */</span><br><span class="line">    public void declareOutputFields(OutputFieldsDeclarer declarer) &#123;</span><br><span class="line">        // TODO Auto-generated method stub</span><br><span class="line">        //声明一个输出流，其中tuple包括了单词和对应的计数，向后发射</span><br><span class="line">        //其他bolt可以订阅这个数据流进一步处理</span><br><span class="line">        declarer.declare(new Fields(&quot;word&quot;,&quot;count&quot;));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>新建类ReportBolt.java（报告生成器）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.Collections;</span><br><span class="line">import java.util.HashMap;</span><br><span class="line">import java.util.Map;</span><br><span class="line"></span><br><span class="line">import org.apache.storm.task.OutputCollector;</span><br><span class="line">import org.apache.storm.task.TopologyContext;</span><br><span class="line">import org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line">import org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line">import org.apache.storm.tuple.Tuple;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 生成一份报告</span><br><span class="line"> * @author soul</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public class ReportBolt extends BaseRichBolt &#123;</span><br><span class="line"></span><br><span class="line">    private HashMap&lt;String, Long&gt; counts = null;//保存单词和对应的计数</span><br><span class="line"></span><br><span class="line">    public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) &#123;</span><br><span class="line">        // TODO Auto-generated method stub</span><br><span class="line"></span><br><span class="line">        this.counts = new HashMap&lt;String, Long&gt;();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void execute(Tuple input) &#123;</span><br><span class="line">        // TODO Auto-generated method stub</span><br><span class="line"></span><br><span class="line">        String word = input.getStringByField(&quot;word&quot;);</span><br><span class="line">        Long count = input.getLongByField(&quot;count&quot;);</span><br><span class="line">        this.counts.put(word, count);</span><br><span class="line"></span><br><span class="line">        //实时输出</span><br><span class="line">        System.out.println(&quot;结果:&quot;+this.counts);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void declareOutputFields(OutputFieldsDeclarer declarer) &#123;</span><br><span class="line">        // TODO Auto-generated method stub</span><br><span class="line">        //这里是末端bolt，不需要发射数据流，这里无需定义</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * cleanup是IBolt接口中定义</span><br><span class="line">     * Storm在终止一个bolt之前会调用这个方法</span><br><span class="line">     * 本例我们利用cleanup()方法在topology关闭时输出最终的计数结果</span><br><span class="line">     * 通常情况下，cleanup()方法用来释放bolt占用的资源，如打开的文件句柄或数据库连接</span><br><span class="line">     * 但是当Storm拓扑在一个集群上运行，IBolt.cleanup()方法不能保证执行（这里是开发模式，生产环境不要这样做）。</span><br><span class="line">     */</span><br><span class="line">    public void cleanup()&#123;</span><br><span class="line">        System.out.println(&quot;---------- FINAL COUNTS -----------&quot;);</span><br><span class="line"></span><br><span class="line">        ArrayList&lt;String&gt; keys = new ArrayList&lt;String&gt;();</span><br><span class="line">        keys.addAll(this.counts.keySet());</span><br><span class="line">        Collections.sort(keys);</span><br><span class="line">        for(String key : keys)&#123;</span><br><span class="line">            System.out.println(key + &quot; : &quot; + this.counts.get(key));</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(&quot;----------------------------&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>修改程序主入口App.java<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.storm.Config;</span><br><span class="line">import org.apache.storm.LocalCluster;</span><br><span class="line">import org.apache.storm.topology.TopologyBuilder;</span><br><span class="line">import org.apache.storm.tuple.Fields;</span><br><span class="line">import org.apache.storm.utils.Utils;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 实现单词计数topology</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public class App </span><br><span class="line">&#123;</span><br><span class="line">    private static final String SENTENCE_SPOUT_ID = &quot;sentence-spout&quot;;</span><br><span class="line">    private static final String SPLIT_BOLT_ID = &quot;split-bolt&quot;;</span><br><span class="line">    private static final String COUNT_BOLT_ID = &quot;count-bolt&quot;;</span><br><span class="line">    private static final String REPORT_BOLT_ID = &quot;report-bolt&quot;;</span><br><span class="line">    private static final String TOPOLOGY_NAME = &quot;word-count-topology&quot;;</span><br><span class="line"></span><br><span class="line">    public static void main( String[] args ) //throws Exception</span><br><span class="line">    &#123;</span><br><span class="line">        //System.out.println( &quot;Hello World!&quot; );</span><br><span class="line">        //实例化spout和bolt</span><br><span class="line"></span><br><span class="line">        SentenceSpout spout = new SentenceSpout();</span><br><span class="line">        SplitSentenceBolt splitBolt = new SplitSentenceBolt();</span><br><span class="line">        WordCountBolt countBolt = new WordCountBolt();</span><br><span class="line">        ReportBolt reportBolt = new ReportBolt();</span><br><span class="line"></span><br><span class="line">        TopologyBuilder builder = new TopologyBuilder();//创建了一个TopologyBuilder实例</span><br><span class="line"></span><br><span class="line">        //TopologyBuilder提供流式风格的API来定义topology组件之间的数据流</span><br><span class="line"></span><br><span class="line">        //builder.setSpout(SENTENCE_SPOUT_ID, spout);//注册一个sentence spout</span><br><span class="line"></span><br><span class="line">        //设置两个Executeor(线程)，默认一个</span><br><span class="line">        builder.setSpout(SENTENCE_SPOUT_ID, spout,2);</span><br><span class="line"></span><br><span class="line">        // SentenceSpout --&gt; SplitSentenceBolt</span><br><span class="line"></span><br><span class="line">        //注册一个bolt并订阅sentence发射出的数据流，</span><br><span class="line">        //shuffleGrouping方法告诉Storm要将SentenceSpout发射的tuple随机均匀的分发给SplitSentenceBolt的实例</span><br><span class="line">        //builder.setBolt(SPLIT_BOLT_ID, splitBolt).shuffleGrouping(SENTENCE_SPOUT_ID);</span><br><span class="line"></span><br><span class="line">        //SplitSentenceBolt单词分割器设置4个Task，2个Executeor(线程)</span><br><span class="line">        builder.setBolt(SPLIT_BOLT_ID, splitBolt,2).setNumTasks(4).shuffleGrouping(SENTENCE_SPOUT_ID);</span><br><span class="line"></span><br><span class="line">        // SplitSentenceBolt --&gt; WordCountBolt</span><br><span class="line"></span><br><span class="line">        //fieldsGrouping将含有特定数据的tuple路由到特殊的bolt实例中</span><br><span class="line">        //这里fieldsGrouping()方法保证所有“word”字段相同的tuuple会被路由到同一个WordCountBolt实例中</span><br><span class="line">        //builder.setBolt(COUNT_BOLT_ID, countBolt).fieldsGrouping( SPLIT_BOLT_ID, new Fields(&quot;word&quot;));</span><br><span class="line"></span><br><span class="line">        //WordCountBolt单词计数器设置4个Executeor(线程)</span><br><span class="line">        builder.setBolt(COUNT_BOLT_ID, countBolt,4).fieldsGrouping( SPLIT_BOLT_ID, new Fields(&quot;word&quot;));</span><br><span class="line"></span><br><span class="line">        // WordCountBolt --&gt; ReportBolt</span><br><span class="line"></span><br><span class="line">        //globalGrouping是把WordCountBolt发射的所有tuple路由到唯一的ReportBolt</span><br><span class="line">        builder.setBolt(REPORT_BOLT_ID, reportBolt).globalGrouping(COUNT_BOLT_ID);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        Config config = new Config();</span><br><span class="line">        //Config类是一个HashMap&lt;String,Object&gt;的子类，用来配置topology运行时的行为</span><br><span class="line">        //设置worker数量</span><br><span class="line">        //config.setNumWorkers(2);</span><br><span class="line">        LocalCluster cluster = new LocalCluster();</span><br><span class="line"></span><br><span class="line">        //本地提交</span><br><span class="line">        cluster.submitTopology(TOPOLOGY_NAME, config, builder.createTopology());</span><br><span class="line"></span><br><span class="line">        Utils.sleep(10000);</span><br><span class="line">        cluster.killTopology(TOPOLOGY_NAME);        </span><br><span class="line">        cluster.shutdown();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>参考资料：<br><a href="http://storm.apache.org/about/integrates.html" target="_blank" rel="noopener">http://storm.apache.org/about/integrates.html</a><br><a href="https://www.cnblogs.com/langtianya/p/5199529.html" target="_blank" rel="noopener">https://www.cnblogs.com/langtianya/p/5199529.html</a><br><a href="https://blog.csdn.net/uisoul/article/details/77990260" target="_blank" rel="noopener">https://blog.csdn.net/uisoul/article/details/77990260</a><br><a href="https://blog.csdn.net/uisoul/article/details/77989927" target="_blank" rel="noopener">https://blog.csdn.net/uisoul/article/details/77989927</a><br><a href="https://blog.csdn.net/CSDN_WANGQI/article/details/53306603" target="_blank" rel="noopener">https://blog.csdn.net/CSDN_WANGQI/article/details/53306603</a><br><a href="https://blog.csdn.net/csdn_wangqi/article/details/53317095" target="_blank" rel="noopener">https://blog.csdn.net/csdn_wangqi/article/details/53317095</a><br><a href="https://blog.csdn.net/qq_37095882/article/category/7055953" target="_blank" rel="noopener">https://blog.csdn.net/qq_37095882/article/category/7055953</a><br><a href="https://blog.csdn.net/cuihaolong/article/details/52652686" target="_blank" rel="noopener">https://blog.csdn.net/cuihaolong/article/details/52652686</a><br><a href="https://www.jianshu.com/p/7e5fc624861b" target="_blank" rel="noopener">https://www.jianshu.com/p/7e5fc624861b</a></p>
<h3 id="再来看看spark"><a href="#再来看看spark" class="headerlink" title="再来看看spark"></a>再来看看spark</h3><p>算了，先等等，后面来填坑，先看openShift</p>
<h3 id="openshift"><a href="#openshift" class="headerlink" title="openshift"></a>openshift</h3><p>OpenShift是由红帽推出逇一款面向开源开发人员开放的平台即服务(PaaS 将服务器平台或者开发环境作为服务)。 OpenShift通过为开发人员提供在语言、框架和云上的更多的选择，使开发人员可以构建、测试、运行和管理他们的应用。它支持用于Java、 Python、PHP、Perl和Ruby的更多的开发框架，包括 Spring、Seam、Weld、CDI、Rails、Rack、Symfony、Zend Framework、Twisted、Django和Java E。它包含SQL和NoSQL数据存储和一个分布式文件系统。其实对比分布式计算要解决的问题以及场景，openshift跟分布式计算都没有什么关系，我觉得它适用于app的分布式部署，不涉及计算，也不涉及mapReduce的过程。但是还是根据资料，记录一下，也许以后用得到。。。<br>openShift部署过程支持依靠Git，jenkins，Maven等标准开源部署工具，集成在IDE中进行代码上传部署。Red Hat给每个用户三枚免费的Gear,可以用Gear运行你的应用。每个用户能免费使用总共 1.5 GB 内存和 3 GB 硬盘空间。<br>OpenShift容器平台有一个基于微服务的架构，它是一个小型的、解耦的单元，可以协同工作。它运行在Kubernetes集群的顶部，有关于存储在etcd中的对象的数据，这是一个可靠的集群键值存储。这些服务被功能分解了:</p>
<p>1.REST api，它公开了每个核心对象。<br>2.控制器读取这些api，对其他对象应用更改，并报告状态或写回对象。</p>
<p>用户对REST API进行调用，以更改系统的状态。控制器使用REST API来读取用户想要的状态，然后尝试将系统的其他部分进行同步。例如，当用户请求一个构建时，他们会创建一个“构建”对象。构建控制器看到已经创建了一个新的构建，并在集群上运行一个进程来执行该构建。当构建完成时，控制器将通过REST API更新构建对象，用户看到他们的构建完成了。</p>
<p>现如今，openShift大多数都结合docker进行配合使用。</p>
<p>自动构建和部署应用：这怎么实现<br>OpenShift V3提供了3种来自动构建应用的方法。<br>Docker-File模式：通过向OpenShift提供指向Docker-File以及其依附关系的源码管理器的URI来自动构建一个Docker容器。<br><img src="../../../../images/openshift1.png" alt="sample"><br>Source-To-Image模式（STI）：允许通过提交应用的源码到OpenShift来自动构建一个应用。（就像Heroku中的buildpacks）。<br><img src="../../../../images/openshift2.png" alt="sample"><br>自定义构建模式：允许提供自己的应用来构建逻辑，这是通过提供一个OpenShift Docker的镜像实现的。<br><img src="../../../../images/openshift3.png" alt="sample"></p>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'http-miccall-tech'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://yoursite.com/2018/06/17/openshift/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://yoursite.com/2018/06/17/openshift/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//http-miccall-tech.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Design: <a href="http://miccall.tech " style="border-bottom: none;">miccall</a></li>
            </ul>
            
            	<span id="busuanzi_container_site_pv">2018总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
</body>



 	
</html>
<script type="text/javascript" src="/js/love.js"></script>